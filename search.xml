<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[openstack newton 安装]]></title>
      <url>%2F2016%2F12%2F12%2Fopenstack-newton-%E5%AE%89%E8%A3%85%2F</url>
      <content type="text"><![CDATA[环境配置机器配置：3台8v8G的虚拟机，1台做控制节点2台做融合节点。 网络划分：192.168.122.0/24 public网络192.168.3.0/24 存储网络192.168.4.0/24管理网络、sdn隧道网络 我这里配置了本地源，就不用在手动配置官网源本地源的搭建和配置会在另外一个文档说明。节点网络信息 ： 管理网络和随道网络 存储网络 公网 控制节点 192.168.4.6 192.168.3.5 192.168.122.2 计算节点 192.168.4.7 192.168.3.6 192.168.125.5 计算节点 192.168.4.8 192.168.3.7 192.168.122.6 网络拓扑 安装chrony控制节点向外同步时间，其他节点如计算节点都直接同步控制节点yum install chrony 修改配置文件vim /etc/chrony.conf添加下面这两条server cn.ntp.org.cn iburstallow 192.168.4.0/24 设置开机启动systemctl enable chronysystemctl start chrony 其他节点：yum install chrony 修改配置文件vim /etc/chrony.conf 添加下面这两条server 192.168.4.6 iburst 设置开机启动systemctl enable chrony 启动进程systemctl start chrony 安装openstack客户端yum install python-openstackclient 安装Mariadb（数据库服务）vim /etc/my.cnf.d/openstack.cnf1234567[mysqld] bind-address = 192.168.4.6 #填写管理网段ip default-storage-engine = innodb innodb_file_per_table max_connections = 4096collation-server = utf8_general_cicharacter-set-server = utf8 设置开机启动 systemctl enable mariadb 启动Mariadb systemctl start mariadb 安装rabbitmq（用于消息队列）yum install rabbitmq-server 设置开机启动 systemctl enable rabbitmq-server开启rabbitmq systemctl start rabbitmq-server 创建openstack用户和配置密码 rabbitmqctl add_user openstack 123456 给openstack用户配置读和写权限 set_permissions openstack ".*" ".*" ".*" ```12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 # 安装memcache（缓存token） yum install memcached phython-memcached systemctl enable memcached systemctl start memcached # 安装keystone（认证服务）连接数据库 [root@control-node1 yum.repos.d]# mysql 创建keystone数据库 create database keystone; 数据库授权 密码自己设置，这里为了方便设置123456 grant all privileges on keystone.* to &apos;keystone&apos;@&apos;localhost&apos; identified by &apos;123456&apos;; grant all privileges on keystone.* to &apos;keystone&apos;@&apos;%&apos; identified by &apos;123456&apos;; keystone使用httpd的mod_wsgi运行在端口5000和35357处理认证服务请求。默认情况下，keystone服务依然监听在5000和35357端口。 安装 keystone和wsgi yum install openstack-keystone httpd mod_wsgi 修改keystone配置文件 vim /etc/keystone/keystone.conf connection = mysql+pymysql://keystone:123456@192.168.4.6/keystone #加入连接数据库配置 配置使用哪种产生token方式目前keystone支持4种(UUID、PKI、PKIZ、Fernet)这里我们配置fernet http://www.tuicool.com/articles/jQJNFrn 这篇文章有几种模式的详细介绍。 [token] provider = fernet 同步数据库 su -s /bin/sh -c &quot;keystone-manage db_sync&quot; keystone #发现同步数据库就是错了也没有反应，需要检查keystone的日志文件查看是否正确 初始化fernet key keystone-manage fernet_setup --keystone-user keystone --keystone-group keystonekeystone-manage credential_setup --keystone-user keystone --keystone-group keystoen创建Bootstrap the Identity service(就是创建admin用户的帐号信息) keystone-manage bootstrap –bootstrap-password 123456 \–bootstrap-admin-url http://192.168.4.6:35357/v3/ \–bootstrap-internal-url http://192.168.4.6:35357/v3/ \–bootstrap-public-url http://192.168.122.2:5000/v3/ \–bootstrap-region-id RegionOne12345678910111213141516配置apache服务器 vim /etc/httpd/conf/httpd.conf配置成管理网段的ip ServerName 192.168.4.6 将keystone的配置文件软链接到apache的配置文件 ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/设置开机启动 systemctl enable httpd 启动httpd systemctl start httpd检查端口 lsof -i:5000COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEhttpd 18883 root 6u IPv6 57978 0t0 TCP :commplex-main (LISTEN)httpd 18894 apache 6u IPv6 57978 0t0 TCP :commplex-main (LISTEN)httpd 18895 apache 6u IPv6 57978 0t0 TCP :commplex-main (LISTEN)httpd 18896 apache 6u IPv6 57978 0t0 TCP :commplex-main (LISTEN)httpd 18897 apache 6u IPv6 57978 0t0 TCP :commplex-main (LISTEN)httpd 18898 apache 6u IPv6 57978 0t0 TCP :commplex-main (LISTEN) 12到root下创建环境变量文件 vim /root/openrc #!/bin/bashexport OS_USERNAME=adminexport OS_PASSWORD=123456 #这个密码是上面Bootstrap the Identity service填的密码export OS_PROJECT_NAME=adminexport OS_USER_DOMAIN_NAME=defaultexport OS_PROJECT_DOMAIN_NAME=defaultexport OS_AUTH_URL=http://192.168.4.6:35357/v3export OS_IDENTITY_API_VERSION=312345678910111213141516171819202122232425262728293031323334353637创建域、项目、用户 创建service project openstack project create --domain default --description &quot;Service Project&quot; service创建user角色 openstack role create user 这里不创建普通用户了 测试admin用户获取tokenopenstack --os-auth-url http://192.168.4.6:35357/v3 token issue ![](http://ohx02qrb8.bkt.clouddn.com/keystone.png)# 安装glance镜像服务连接Mariadb创建数据库 create database glance;授权 grant all privileges on glance.* to &apos;glance&apos;@&apos;localhost&apos; identified by &apos;123456&apos;; grant all privileges on glance.* to &apos;glance&apos;@&apos;%&apos; identified by &apos;123456&apos;; grant all privileges on glance.* to &apos;glance&apos;@&apos;control-node1.novalocal&apos; identified by &apos;123456&apos;; - control-xxx换成主机名，我这里就算api.conf里面配置的ip默认还是去连接host是主机名，所以只能在加个主机名授权。创建glance用户并设置密码 openstack user create --domain default --password-prompt glance 给glance用户添加admin角色权限 openstack role add --project service --user glance admin 创建glance service openstack service create --name glance --description &quot;OpenStack Image&quot; image 创建glance endpoint openstack endpoint create –region RegionOne image public http://192.168.122.2:9292openstack endpoint create –region RegionOne image internal http://192.168.4.6:9292openstack endpoint create –region RegionOne image admin http://192.168.4.6:92921234567安装软件包 yum install openstack-glance 配置glance vim /etc/glance/glance-api.conf配置数据库 [database]connection = mysql+pymysql://glance:123456@192.168.4.6/glance1234配置glancevim /etc/glance/glance-api.conf配置数据库 [database]connection = mysql+pymysql://glance:123456@192.168.4.6/glance配置keystone[keystone_authtoken]auth_uri = http://192.168.4.6:5000auth_url = http://192.168.4.6:35357memcached_servers = 192.168.4.6:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = glancepassword = 123456 [paste_deploy]flavor = keystone12配置镜像存储 [glance_store]stores = file,httpdefault_store = filefilesystem_store_datadir = /var/lib/glance/images/12vim /etc/glance/glance-registry.conf [database]connection = mysql+pymysql://glance:123456@192.168.4.6/glance配置keystone[keystone_authtoken]auth_uri = http://192.168.4.6:5000auth_url = http://192.168.4.6:35357memcached_servers = 192.168.4.6:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = glancepassword = 123456 [paste_deploy]flavor = keystone12345678910111213同步数据库 su -s /bin/sh -c &quot;glance-manage db_sync&quot; glance 设置开机启动 systemctl enable openstack-glance-api 启动服务 systemctl start openstack-glance-api 这些做完后最好在查看下日志，看看是否有错误，每部署完一个组件都这样，这样出错的可以很快定位。 下载cirros测试一下 wget http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.imgopenstack image create “cirros” –file cirros-0.3.4-x86_64-disk.img –disk-format qcow2 –container-format bare –public1234567891011121314151617181920212223242526272829303132333435363738394041424344454647![](http://ohx02qrb8.bkt.clouddn.com/glance.png)glance image-list 检查一下镜像是否上传成功 ![](http://ohx02qrb8.bkt.clouddn.com/glance-2.png)# 安装nova组件### 控制节点安装创建数据库 create database nova_api; create database nova; 授权GRANT ALL PRIVILEGES ON nova_api.* TO &apos;nova&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123456&apos;; GRANT ALL PRIVILEGES ON nova_api.* TO &apos;nova&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;; GRANT ALL PRIVILEGES ON nova_api.* TO &apos;nova&apos;@&apos;control-node1.novalocal&apos; IDENTIFIED BY &apos;123456&apos;; GRANT ALL PRIVILEGES ON nova.* TO &apos;nova&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123456&apos;; GRANT ALL PRIVILEGES ON nova.* TO &apos;nova&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;; GRANT ALL PRIVILEGES ON nova.* TO &apos;nova&apos;@&apos;control-node1.novalocal&apos; IDENTIFIED BY &apos;123456&apos;; 创建为nova组件创建用户、service、endpoint openstack user create --domain default --password-prompt nova 给nova用户添加admin角色权限 openstack role add --project service --user nova admin 创建service openstack service create --name nova --description &quot;OpenStack Compute&quot; compute 创建endpoint openstack endpoint create --region RegionOne compute public http://192.168.122.2:8774/v2.1/%\(tenant_id\)s openstack endpoint create --region RegionOne compute internal http://192.168.4.6:8774/v2.1/%\(tenant_id\)s openstack endpoint create --region RegionOne compute admin http://192.168.4.6:8774/v2.1/%\(tenant_id\)s 安装nova-api组件 yum install openstack-nova-api openstack-nova-conductor openstack-nova-console openstack-nova-novncproxy openstack-nova-scheduler配置nova vim /etc/nova/nova.conf [DEFAULT]transport_url = rabbit://openstack:123456@192.168.4.6 #配置rabbitmq帐户和密码my_ip = 192.168.4.6use_neutron = Truefirewall_drive = nova.virt.firewall.NoopFirewallDriverenabled_apis=osapi_compute,metadataauth_strategy=keystone [api_database]connection = mysql+pymysql://nova:123456@192.168.4.6/nova_api #配置nova连接数据库 [database]connection = mysql+pymysql://nova:123456@192.168.4.6/nova [keystone_authtoken]auth_uri = http://192.168.4.6:5000auth_url = http://192.168.4.6:35357memcached_servers = 192.168.4.6:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = novapassword = 123456配置novncnovncproxy_port=6080novncproxy_base_url=http://211.156.182.144:6080/vnc_auto.htmlvncserver_listen=192.168.4.6[glance]api_servers = http://192.168.4.6:9292 [oslo_concurrency]lock_path = /var/lib/nova/tmp1234同步数据库 su -s /bin/sh -c &quot;nova-manage api_db sync&quot; nova su -s /bin/sh -c &quot;nova-manage db sync&quot; nova systemctl enable openstack-nova-api.service \openstack-nova-consoleauth.service \openstack-nova-scheduler.service \openstack-nova-conductor.service \openstack-nova-novncproxy.service systemctl start openstack-nova-api.service \openstack-nova-consoleauth.service \openstack-nova-scheduler.service \openstack-nova-conductor.service \openstack-nova-novncproxy.service 1234567### 计算机节点安装安装nova-compute yum install openstack-nova-compute 配置nova-compute vim /etc/nova/nova.conf [DEFAULT]enabled_apis = osapi_compute,metadatatransport_url = rabbit://openstack:123456@192.168.4.6 #配置rabbitmq帐号和密码auth_strategy = keystonemy_ip = 192.168.4.7use_neutron = Truefirewall_driver = nova.virt.firewall.NoopFirewallDriver [keystone_authtoken]auth_uri = http://192.168.4.6:5000auth_url = http://192.168.4.6:35357memcached_servers = 192.168.4.6:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = novapassword = 123456[vnc]enabled=truevncserver_listen=0.0.0.0vncserver_proxyclient_address=192.168.4.7 #填写本机ipnovncproxy_base_url=http://211.156.182.144:6080/vnc_auto.html #这个填你要用控制节点的public ip [glance]api_servers = http://192.168.4.6:9292 配置锁路径[oslo_concurrency]lock_path = /var/lib/nova/tmp [libvirt]virt_type = qemu #物理服务器就配置kvm虚拟机就配置qemu 1234567891011121314151617181920212223242526272829303132333435363738394041424344设置开机启动 systemctl enable libvirtd.service openstack-nova-compute.service 启动nova-compute systemctl start libvirtd.service openstack-nova-compute.service 在控制节点查看检查一下compute进程根控制节点连接 ![](http://ohx02qrb8.bkt.clouddn.com/nova-compute.png)# 配置neutron### 控制节点安装我这里使用openvswitch不使用linux bridge，因为openvswitch功能比linux Brige功能强太多了。但配置稍微复杂点。 创建数据库create database neutron; GRANT ALL PRIVILEGES ON neutron.* TO &apos;neutron&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123456&apos;; GRANT ALL PRIVILEGES ON neutron.* TO &apos;neutron&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;; GRANT ALL PRIVILEGES ON neutron.* TO &apos;neutron&apos;@&apos;control-node1.novalocal&apos; IDENTIFIED BY &apos;123456&apos;; 创建neutron用户并设置密码 openstack user create --domain default --password-prompt neutron 给neutron用户添加admin角色权限 openstack role add --project service --user neutron admin 创建neutron service openstack service create --name neutron --description &quot;OpenStack Networking&quot; network 创建neutron endpoint openstack endpoint create --region RegionOne network public http://192.168.122.2:9696 openstack endpoint create --region RegionOne network admin http://192.168.4.6:9696 openstack endpoint create --region RegionOne network internal http://192.168.4.6:9696 安装neutron组件 yum -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch vim /etc/neutron/neutron.conf [DEFAULT]service_plugins = routertransport_url = rabbit://openstack:123456@192.168.4.6auth_strategy = keystonenotify_nova_on_port_status_changes = Truenotify_nova_on_port_data_changes = Truestate_path = /var/lib/neutronuse_syslog = Truesyslog_log_facility = LOG_LOCAL4log_dir =/var/log/neutroncore_plugin = neutron.plugins.ml2.plugin.Ml2Pluginbase_mac = fa:16:3e:00:00:00mac_generation_retries = 32dhcp_lease_duration = 600dhcp_agent_notification = Trueallow_bulk = Trueallow_pagination = Falseallow_sorting = Falseallow_overlapping_ips = Trueadvertise_mtu = Trueagent_down_time = 30router_scheduler_driver = neutron.scheduler.l3_agent_scheduler.ChanceSchedulerallow_automatic_l3agent_failover = Truedhcp_agents_per_network = 2api_workers = 9rpc_workers = 9network_device_mtu=1450 [database]connection = mysql+pymysql://neutron:123456@192.168.4.6/neutron [keystone_authtoken]auth_uri = http://192.168.4.6:5000auth_url = http://192.168.4.6:35357memcached_servers = 192.168.4.6:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = 123456 [nova]auth_url = http://192.168.4.6:35357auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = novapassword = 123456[oslo_concurrency]lock_path = /var/lib/neutron/tmp1234配置modular layer 2（ml2）插件 vim /etc/neutron/plugins/ml2/ ml2_conf.ini [DEFAULT]type_drivers = flat,vxlantenant_network_types = vxlanmechanism_drivers = openvswitch,l2populationextension_drivers = port_security [ml2]path_mtu = 1450type_drivers = flat,vxlantenant_network_types = vxlanphysical_network_mtus =physnet1:1500 [ml2_type_flat]flat_networks =* [ml2_type_vxlan]vni_ranges =2:65535vxlan_group =224.0.0.1 [securitygroup]enable_security_group = Truefirewall_driver=neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver [ovs]local_ip=192.168.4.6tunnel_bridge=br-tunenable_tunneling=Trueintegration_bridge=br-intbridge_mappings=physnet1:br-ex12345678910111213141516配置l3-agent vim /etc/neutron/l3_agent.ini [DEFAULT]debug = Falseinterface_driver =neutron.agent.linux.interface.OVSInterfaceDriverhandle_internal_only_routers = Truemetadata_port = 8775send_arp_for_ha = 3periodic_interval = 40periodic_fuzzy_delay = 5enable_metadata_proxy = Truerouter_delete_namespaces = True配置dhcp_agentvim /etc/neutron/dhcp_agent.ini [DEFAULT]resync_interval = 30interface_driver =neutron.agent.linux.interface.OVSInterfaceDriverenable_isolated_metadata = Trueenable_metadata_network = Falsedhcp_domain = openstacklocaldhcp_broadcast_reply = Falsedhcp_delete_namespaces = Trueroot_helper=sudo neutron-rootwrap /etc/neutron/rootwrap.confstate_path=/var/lib/neutron1vim /etc/neutron/plugins/ml2/openvswitch_agent.ini [agent]polling_interval = 2tunnel_types = vxlanvxlan_udp_port = 4789l2_population = Trueprevent_arp_spoofing = Falseextensions =[ovs]local_ip=192.168.4.6tunnel_bridge=br-tunenable_tunneling=Trueintegration_bridge=br-intbridge_mappings=physnet1:br-ex [securitygroup]firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriverenable_security_group = true 123456789101112131415161718192021222324设置openvswitch开机启动 systemctl enable openvswitch.service 启动openvswitch systemctl start openvswitch 创建br-ex br-tun br-int ovs-vsctl add-br br-int ovs-vsctl add-br br-ex ovs-vsctl add-br br-tun 将上外网网卡挂载到br-ex上 ovs-vsctl add-port br-ex eth2设置开机启动项 systemctl enable neutron-openvswitch-agent.service 启动进程 systemctl start neutron-openvswitch-agent.service ### 配置计算节点neutron配置一下内核参数修改配置文件 /etc/sysctl.conf net.ipv4.conf.all.rp_filter=0net.ipv4.conf.default.rp_filter=01234sysctl –pyum -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch vim /etc/neutron/neutron.conf [DEFAULT]transport_url = rabbit://openstack:123456@192.168.4.6auth_strategy = keystone [keystone_authtoken]auth_uri = http://192.168.4.6:5000auth_url = http://192.168.4.6:35357memcached_servers = 192.168.4.6:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = neutronpassword = 123456 [oslo_concurrency]lock_path = /var/lib/neutron/tmp vim /etc/neutron/plugins/ml2/ml2_conf.ini [ml2]path_mtu = 1450type_drivers = flat,vxlantenant_network_types = vxlanphysical_network_mtus =physnet1:1500mechanism_drivers = openvswitch,l2populationextension_drivers = port_security [securitygroup]enable_ipset = truefirewall_driver=neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver vim /etc/neutron/plugins/ml2/openvswitch_agent.ini [ovs]local_ip=192.168.4.7tunnel_bridge=br-tunenable_tunneling=Trueintegration_bridge=br-intbridge_mappings=physnet1:br-ex [agent]enable_distributed_routing=Trueprevent_arp_spoofing=Truearp_responder=Truepolling_interval=2drop_flows_on_start=Falsevxlan_udp_port=4789l2_population=Truetunnel_types=vxlan [securitygroup]firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriverenable_security_group = true 123456789systemctl enable openvswitch.service systemctl start openvswitch.service 创建br-ex、br-int、br-tun ovs-vsctl add-br br-int ovs-vsctl add-br br-ex ovs-vsctl add-br br-tun vim /etc/nova/nova.conf [DEFAULT]network_api_class = nova.network.neutronv2.api.APIsecurity_group_api = neutronlinuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver [neutron]url = http://192.168.4.6:9696auth_url = http://192.168.4.6:35357auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultregion_name = RegionOneproject_name = serviceusername = neutronpassword = 1234561234567891011systemctl restart neutron-openvswitch-agent.service systemctl restart openstack-nova-compute 安装完后可以在在控制节点检查是否安装成功 ![](http://ohx02qrb8.bkt.clouddn.com/neutron.png)# 安装控制台yum install openstack-dashboard vim /etc/openstack-dashboard/local_settings 这里配置控制节点ipOPENSTACK_HOST = “192.168.4.6”配置允许所有节点访问ALLOWED_HOSTS = [‘*’, ]配置memcacheSESSION_ENGINE = ‘django.contrib.sessions.backends.cache’CACHES = { ‘default’: { ‘BACKEND’: ‘django.core.cache.backends.memcached.MemcachedCache’, ‘LOCATION’: ‘192.168.4.6:11211’, }} 配置keystone v3验证OPENSTACK_KEYSTONE_URL = “http://%s:5000/v3“ % OPENSTACK_HOST配置域OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = ‘default’ 配置api版本OPENSTACK_API_VERSIONS = { “identity”: 3, “image”: 2, “volume”: 2,} 设置通过控制台默认创建用户的角色是userOPENSTACK_KEYSTONE_DEFAULT_ROLE = “user” 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647重启服务 systemctl restart httpd.service memcached.service 通过http://control_ip/dashboard可以访问 ![](http://ohx02qrb8.bkt.clouddn.com/dashboard.png)Admin 登录，密码是你通过keystone创建的，如果不记得查看openrc ![](http://ohx02qrb8.bkt.clouddn.com/dashboard-2.png)![](http://ohx02qrb8.bkt.clouddn.com/dashboard-2.png)创建flat网络做float_ip池 管理员—&gt;网络——&gt;创建网络 Phynet1是在ml2.ini里面bridge_mappings定义的br-ex对应的名字，创建完后增加子网，然后在创建个普通网络，创建个路由器，路由器绑定普通子网，创建个主机配置，然后创建vm加入到你创建的普通网络 ![](http://ohx02qrb8.bkt.clouddn.com/dashboard-4.png) 这时在vm所在的计算节点或控制节点 ovs-vsctl show ![](http://ohx02qrb8.bkt.clouddn.com/dashboard-5.png) 可以看见计算节点根网络节道隧道已经建立。 # Cinder配置创建数据库 create database cinder; 用户授权 GRANT ALL PRIVILEGES ON cinder.* TO &apos;cinder&apos;@&apos;localhost&apos; identified by &apos;123456&apos;; GRANT ALL PRIVILEGES ON cinder.* TO &apos;cinder&apos;@&apos;%&apos; identified by &apos;123456&apos;; GRANT ALL PRIVILEGES ON cinder.* TO &apos;cinder&apos;@&apos;control-node1.novalocal&apos; identified by &apos;123456&apos;; 创建用户 openstack user create --domain default --password-prompt cinder 给cinder用户赋予admin权限 openstack role add --project service --user cinder admin openstack service create --name cinder --description &quot;OpenStack Block Storage&quot; volume openstack service create --name cinderv2 --description &quot;OpenStack Block Storage&quot; volumev2 创建endpoint openstack endpoint create –region RegionOne \volume public http://192.168.122.2:8776/v1/%\(tenant_id\)s openstack endpoint create –region RegionOne \volume internal http://192.168.4.6:8776/v1/%\(tenant_id\)s openstack endpoint create –region RegionOne \volume admin http://192.168.4.6:8776/v1/%\(tenant_id\)s openstack endpoint create –region RegionOne \volumev2 public http://192.168.122.2:8776/v2/%\(tenant_id\)s openstack endpoint create –region RegionOne \volumev2 internal http://192.168.4.6:8776/v2/%\(tenant_id\)s openstack endpoint create –region RegionOne \volumev2 admin http://192.168.4.6:8776/v2/%\(tenant_id\)s12345安装cinder yum install openstack-cinder vim /etc/cinder/cinder.conf [DEFAULT]transport_url = rabbit://openstack:123456@192.168.4.6auth_strategy = keystone [database]connection = mysql+pymysql://cinder:123456@192.168.4.6/cinder [keystone_authtoken]auth_uri = http://192.168.4.6:5000auth_url = http://192.168.4.6:35357memcached_servers = 192.168.4.6:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = cinderpassword = 123456 [oslo_concurrency]lock_path = /var/lib/cinder/tmp123456789101112131415161718192021222324252627282930313233同步数据库 su -s /bin/sh -c &quot;cinder-manage db sync&quot; cinder 配置计算机节点使用cinder vim /etc/nova/nova.conf [cinder] os_region_name = RegionOne 重启服务 systemctl restart openstack-nova-api.service 设置开机自启cinder systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service 配置一个存储节点 安装lvm yum install lvm2 systemctl enable lvm2-lvmetad.service systemctl start lvm2-lvmetad.service 创建个lvm卷 pvcreate /dev/vdb 创建vgvgcreate cinder-volumes /dev/vdb 重新配置lvm让它只扫描“cinder-volume”卷组设备 vim /etc/lvm/lvm.confdevices {filter = [ “a/vdb/“, “r/.*/“]12345安装软件 yum install openstack-cinder targetcli python-keystone 修改cinder配置文件 vim /etc/cinder/cinder.conf [DEFAULT]transport_url = rabbit://openstack:123456@192.168.4.6verbose = Trueauth_strategy = keystoneenabled_backends = lvmglance_api_servers = http://192.168.4.6:9292[database]connection = mysql+pymysql://cinder:123456@192.168.4.6/cinder [keystone_authtoken]auth_uri = http://192.168.4.6:5000auth_url = http://192.168.4.6:35357memcached_servers = 192.168.4.6:11211auth_type = passwordproject_domain_name = defaultuser_domain_name = defaultproject_name = serviceusername = cinderpassword = 123456[lvm]volume_driver = cinder.volume.drivers.lvm.LVMVolumeDrivervolume_group = cinder-volumesiscsi_protocol = iscsiiscsi_helper = lioadm [oslo_concurrency]lock_path = /var/lib/cinder/tmp```systemctl enable openstack-cinder-volume.service target.servicesystemctl start openstack-cinder-volume.service target.service 到控制台创建个卷，并挂载到云主机。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Fastnetmon配置与使用]]></title>
      <url>%2F2016%2F12%2F09%2Ffastnetmon%2F</url>
      <content type="text"><![CDATA[Fastnetmon介绍FastNetmon是一个基于多种抓包引擎来对数据包进行统计分析的DOS/DDOS工具，可以探测和分析网络中的异常流量情况，同时，也可以对捕获的异常调用外部脚本进行处理警报啊或者进行阻断处理，全靠外部脚本是如何定义。 项目首页http://www.open-open.com/lib/view/home/143193107973 部署架构 安装和配置方法安装 下载自动安装脚本wget https://raw.githubusercontent.com/FastVPSEestiOu/fastnetmon/master/src/fastnetmon_install.pl -Ofastnetmon_install.pl 将整个项目克隆下来https://github.com/FastVPSEestiOu/fastnetmon 安装注意若安装报连接错误，请将DNS改为8.8.8.8或223.5.5.5，因为下载地址都是在国外，有些DNS可能解析不够好。perl fastnetmon_install.pl 启动安装脚本。 配置 配置文件，cd到你刚刚克隆的项目里面。cp src/Fastnetmon.conf 到/etc/cp src/fastnetmon_init_script_centos6 /etc/init.d/fastnetmon #cp启动脚本到/etc/init.d/chmod 755 /etc/init.d/fastnetmon #修改启动脚本权限cp src/notify_about_attack.sh /usr/local/bin/ #cp 通知脚本 /etc/fastentmon配置项ban_time = 1900 #对检测到攻击的ip进行多久封锁。enable_subnet_counters = on #检测每个子网进出流量enable_connection_tracking = on #开启攻击追踪检测，通过这个选项在日志文件里可以详细看见攻击者ip和其他一些详细情况ban_for_pps = on，ban_for_bandwidth = on，ban_for_flows = on #检测的选项pps(每秒包)，bandwidth(带宽)，flows(流量)。threshold_pps = 20000，threshold_mbps = 1000，threshold_flows = 3500 #监控的限定值抓包引擎选择mirrof=off没有安装PF_RING就不要开启，不然会启动报错。pfring_sampling_ratio = 1 #端口镜像采样率mirror_netmap = off没有安装Netmap就不要开启，不然会会启动报错。mirror_snabbswitch=on #开启snabbswitch流量捕获。mirror_afpacket =on #AF_PACKET捕获引擎开启netmap_sampling_ratio = 1 #端口镜像抽样比pcap=on #pcap引擎开启netflopw=on #使用Netflow捕获方法interfaces=enp5s0f1 #监控的端口，我这里使用的是镜像端口,不然监控不到整个网端流量notify_script_path=/usr/local/bin/notify_about_attack.sh #触发脚本位置monitor_local_ip_addresses = on #监控本地地址sort_parameter = packets #在控制台排序单位，包max_ips_in_list =400 #在控制台显示多少地址 编辑要监控的网段vim /etc/networks_list #编辑networks_list加入要监控的网段这里我加入211.156.182.0/24 220.242.2.0/24/etc/init.d/fastnetmon start #启动fastentmon，启动失败查看/var/log/fastnetmon.log/opt/fastnetmon/fastnetmon #打开监控控制台 修改监控脚本1,要先外发邮件必须配置mailx 安装mailx，配置SMTP vim /etc/mail.rc 我这里配置的是我163的邮箱set bsdcompatset from=xxxxx@163.com smtp=smtp.163.comset smpt-auth-user=xxxx@163.com set smtp-auth-user=xxxxxx@163.com smtp-auth-password=xxxxxx smtp-auth=login vim /usr/local/bin/notify_about_attack.sh #这里填要触发监控的脚本修改邮件地址为接受人。cat | mail -s “FastNetMon Guard: IP $1 blocked because $2 attack with power $3 pps” $email_notify; 测试使用低轨道等离子炮（Loic）进行测试这里我对我们211.156.182.143进行Tcp DDOS攻击我们先把这些值调低threshold_pps = 2000，threshold_mbps = 100，threshold_flows = 350 #监控的限定值然后重启Fastnetmon 测试完修改回值]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hello]]></title>
      <url>%2F2016%2F12%2F06%2Fhello%2F</url>
      <content type="text"><![CDATA[你好,欢迎来到我的个人技术博客.]]></content>
    </entry>

    
  
  
</search>
